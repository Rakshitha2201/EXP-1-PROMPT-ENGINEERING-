# EXP-1-PROMPT-ENGINEERING-

## Aim: 
Comprehensive Report on the Fundamentals of Generative AI and Large Language Models (LLMs)
Experiment: Develop a comprehensive report for the following exercises:

Explain the foundational concepts of Generative AI.
Focusing on Generative AI architectures. (like transformers).
Generative AI applications.
Generative AI impact of scaling in LLMs.

## Algorithm:
**Step 1: Understand the Core Concepts**
Start by defining what Generative AI is and its main goal.

Next, study how it's different from discriminative models (creating vs. classifying).

**Step 2: Research Key Architectures**
Explore major architectures like VAEs and GANs.

Give special attention to the Transformer architecture, as it is the foundation for modern LLMs.

**Step 3: Find Real-World Examples**
Look for practical applications of Generative AI.

Collect examples across text, image, audio, and multimodal generation.

**Step 4: Analyze the Impact of Scaling**
Investigate how increasing a model's size and data affects its performance.

Document key findings, such as emergent capabilities and few-shot learning.

**Step 5: Write the Report**
Organize your findings into a clear and descriptive report.

Summarize the concepts and present your findings on applications and scaling in a concise, easy-to-follow way.

## Output:
https://github.com/Rakshitha2201/EXP-1-PROMPT-ENGINEERING-/blob/main/Rakshitha_prompt_exp1.pdf



## Result:
The report was a success. It provides a clear, comprehensive overview of Generative AI and LLMs.It explains the core concepts and the difference between generative and discriminative models. The report details the crucial Transformer architecture and its real-world applications.Finally, it analyzes the impact of scaling on LLMs, highlighting how larger models gain powerful new abilities.

